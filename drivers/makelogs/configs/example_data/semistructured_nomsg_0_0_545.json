{"index":"rankin-2015.05.15","@timestamp":"2015-05-15T03:17:33.777Z","ip":"135.212.157.163","extension":"gif","response":"503","geo":{"coordinates":{"lat":48.29965139,"lon":-116.5597681},"src":"CN","dest":"IR","srcdest":"CN:IR"},"@tags":["success","security"],"referer":"http://www.slate.com/success/story-musgrave","agent":"Mozilla/5.0 (X11; Linux i686) AppleWebKit/534.24 (KHTML, like Gecko) Chrome/11.0.696.50 Safari/534.24","bytes":0,"host":"motion-media.theacademyofperformingartsandscience.org","request":"/canhaz/takao-doi.gif","url":"https://motion-media.theacademyofperformingartsandscience.org/canhaz/takao-doi.gif","text":" Why are you even considering raid 10 or 5.  You want performance here.  You don't care if the drives just go down, since its a cache only.  Just use raid 0 or keep them separate.  I think separate would be better, since a drive failure wouldn't take down your entire cache. ","machine":{"os":"win xp","ram":10737418240}}
{"index":"rankin-2015.05.13","@timestamp":"2015-05-13T21:21:33.613Z","ip":"185.113.220.2","extension":"gif","response":"200","geo":{"coordinates":{"lat":44.52019417,"lon":-109.0237961},"src":"RU","dest":"RU","srcdest":"RU:RU"},"@tags":["success","info"],"referer":"http://www.slate.com/success/catherine-coleman","agent":"Mozilla/5.0 (X11; Linux i686) AppleWebKit/534.24 (KHTML, like Gecko) Chrome/11.0.696.50 Safari/534.24","bytes":672,"host":"motion-media.theacademyofperformingartsandscience.org","request":"/canhaz/eric-a-boe.gif","url":"https://motion-media.theacademyofperformingartsandscience.org/canhaz/eric-a-boe.gif","text":" As everyone has noted, there are lots of parameters to consider.  The most basic one is power.  Check with your datacenter on the difference in rates for them providing 220V vs 110V power - you might be suprised.  Do they offer an 18V DC option? (this is most often available in datacenters that cater more to telecom gear, as that's been the standard there for decades)  Power supplies exist to let x86 gear run off of all the above.  IIRc, the DC power supplies are most efficient, followed by the 220V and then the 100V.  DC is most efficient because it's just a voltage drop via resistor, not an AC/DC converter as is in AC power supplies (the outputs of a PC power supply are +/-12V and +/-5V, right?).  Sometimes it's even most cost effective to put a per-rack AC/DC converter and then run the AC to the converter in the rack and then short-run the DC power up to the machines.  Besides type of power, there's plain old power use: spinning down unused drive arrays, setting up unused machines to sleep in a low-power mode, or to come online when needed (via remote power control or wake-on-lan) but othewise shut themselves down, virtualization to consolidate workloads into fewer physical machines while maintaining logical separation.  The effects of power consumption trickle all through the equation: less power means less waste heat means less cooling necessary.  It's the cornerstone of going green... but it's also complicated and can be difficult to measure.  My favorite way to be green these days is actually to punt and 'use the cloud'.  Amazon and Google and Rackspace and Linode are better at this than me, and probably better at it than you too.  Figure out how to apply the cloud to your problem, thereby making the entire datacenter-provisioning problem... someone else's. ","machine":{"os":"ios","ram":9663676416}}
{"index":"rankin-2015.05.15","@timestamp":"2015-05-15T19:37:02.380Z","ip":"149.57.67.5","extension":"png","response":"200","geo":{"coordinates":{"lat":46.79738889,"lon":-102.8019528},"src":"DE","dest":"PH","srcdest":"DE:PH"},"@tags":["success","info"],"referer":"http://facebook.com/success/robert-springer","agent":"Mozilla/5.0 (X11; Linux x86_64; rv:6.0a1) Gecko/20110421 Firefox/6.0a1","bytes":5906,"host":"media-for-the-masses.theacademyofperformingartsandscience.org","request":"/uploads/evgeny-tarelkin.png","url":"https://media-for-the-masses.theacademyofperformingartsandscience.org/uploads/evgeny-tarelkin.png","text":" If using active directory    Navigate to C:\\program files\\the win 95 app folder. On security tab (properties) give Domain Users Read and Write Access. I usually avoid the Full Control.    Open Regedit and Navigate to LOCAL MACHINE\\SOFTWARE and find the win 95 app. On permission tab give the Domain Users Read and Write access. Again, I try to avoid the Full Control thing here as well.    Here is an unusual one - then run the app for a minute as if you are one of the users (but logged in as admin) open a few of the screens and so on. Then close the app, and open windows search. Search  for files recently modified with timestamp during the time you were using the app. You may find some .ini which some programmers back then (win 95) put in the windows directory. I go to their properties and give the Domain Users Full Control....NOT ON THE WINDOWS DIRECTORY...JUST THE FILE WHICH BELONGS TO THE APP.    That should do the trick. It worked for me several times. ","machine":{"os":"ios","ram":32212254720}}
{"index":"rankin-2015.05.15","@timestamp":"2015-05-15T04:15:34.310Z","ip":"21.52.224.75","extension":"png","response":"200","geo":{"coordinates":{"lat":34.83398056,"lon":-92.25792778},"src":"IN","dest":"ES","srcdest":"IN:ES"},"@tags":["success","info"],"referer":"http://facebook.com/success/ellen-ochoa","agent":"Mozilla/5.0 (X11; Linux x86_64; rv:6.0a1) Gecko/20110421 Firefox/6.0a1","bytes":8288,"host":"media-for-the-masses.theacademyofperformingartsandscience.org","request":"/uploads/william-s-mcarthur.png","url":"https://media-for-the-masses.theacademyofperformingartsandscience.org/uploads/william-s-mcarthur.png","text":" warpr explained why you have two apache installs. Typically, when you're using a package-based distribution you should look for a packaged version before you install anything from source.  I wouldn't say you can't use the packaged php5 with a compiled apache, but unless you have a good known reason, use the package. It'll save you time and energy.  As for why apache was automatically installed:  from aptitude show php5:  This package is a metapackage that, when installed, guarantees that you have at least one of the three server-side versions of the PHP5 interpreter installed.Depends: libapache2-mod-php5 (&gt;= 5.2.6.dfsg.1-3ubuntu4.1) |         libapache2-mod-php5filter (&gt;= 5.2.6.dfsg.1-3ubuntu4.1) | php5-cgi (&gt;=         5.2.6.dfsg.1-3ubuntu4.1), php5-common (&gt;= 5.2.6.dfsg.1-3ubuntu4.1)  So what happened is Ubuntu installed the most common PHP interpreter, libapache2-mod-php5, which in turn pulled in apache, and so on.  If you want to install php without installing apache, you could install php5-cgi, which you could then use with other http servers. One way to do this would be:  sudo apt-get install php5-cgi php5  which would use php5-cgi as the depends for the php5 package. ","machine":{"os":"win 7","ram":10737418240}}
{"index":"rankin-2015.05.14","@timestamp":"2015-05-14T00:54:05.804Z","ip":"240.224.198.6","extension":"css","response":"404","geo":{"coordinates":{"lat":29.37181222,"lon":-100.9232339},"src":"ZA","dest":"RU","srcdest":"ZA:RU"},"@tags":["success","security"],"referer":"http://facebook.com/success/michael-coats","agent":"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 1.1.4322)","bytes":5768,"host":"cdn.theacademyofperformingartsandscience.org","request":"/styles/ad-blocker.css","url":"https://cdn.theacademyofperformingartsandscience.org/styles/ad-blocker.css","text":" Best thing to do would be to fire up the VMware converter on the physical machine and give it a try.  I used it on a number of V2V migrations when we implemented ESX.  I took a number of MS Virtual Server images and converted them without incident.  For my P2V's though I used an HP tool that in the end I think was more trouble than it was worth.  The client side HAD to be run from an XP machine, and only worked on newer Proliant hardware.    Looking back I wish that I had tried the VMware converter on a P2V.  If you do try it I'd be interested to know how it ends up. ","machine":{"os":"osx","ram":5368709120}}
{"index":"rankin-2015.05.14","@timestamp":"2015-05-14T00:51:49.166Z","ip":"27.90.173.171","extension":"jpg","response":"200","geo":{"coordinates":{"lat":34.28358333,"lon":-80.56486111},"src":"US","dest":"US","srcdest":"US:US"},"@tags":["success","security"],"referer":"http://www.slate.com/success/sergei-ryazanski","agent":"Mozilla/5.0 (X11; Linux x86_64; rv:6.0a1) Gecko/20110421 Firefox/6.0a1","bytes":1835,"host":"media-for-the-masses.theacademyofperformingartsandscience.org","request":"/uploads/barry-wilmore.jpg","url":"https://media-for-the-masses.theacademyofperformingartsandscience.org/uploads/barry-wilmore.jpg","text":" We have a small cluster of Xen servers in the office. Each virtual machine system image is on its own block device on our iSCSI SAN. The servers all connect their iSCSI initiator to every VM LUN simultaneously.   To prevent the same VM from being started on multiple hosts we just ensure that each virtual machine is only added to one server through the use of xm new. Judicious monitoring of all the servers through virt-manager helps as well. However, there really there are no safeguards that would prevent someone from accidentally launching the same VM on multiple hosts.  My question is, what would be a good way to implement a better management system for a setup like this? Are there any existing tools that will manage a Xen setup like this with a shared storage back-end?   We're using openSUSE 11.1 as the host OS. ","machine":{"os":"ios","ram":17179869184}}
{"index":"rankin-2015.05.14","@timestamp":"2015-05-14T07:33:44.400Z","ip":"62.7.255.251","extension":"jpg","response":"200","geo":{"coordinates":{"lat":39.53418583,"lon":-89.32781222},"src":"EG","dest":"CN","srcdest":"EG:CN"},"@tags":["success","security"],"referer":"http://twitter.com/warning/ted-freeman","agent":"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 1.1.4322)","bytes":3465,"host":"media-for-the-masses.theacademyofperformingartsandscience.org","request":"/uploads/sultan-bin-salman-bin-abdulaziz-al-saud.jpg","url":"https://media-for-the-masses.theacademyofperformingartsandscience.org/uploads/sultan-bin-salman-bin-abdulaziz-al-saud.jpg","text":" We have a DB's at 111 and 102GB, respectively, that get backed up in under 30 minutes on a GigE network. I have heard that larger databases can have problems with long-running stored procedures, but have seen no demonstration of it.  A nice quote from The Scaling SharePoint 2007: Storage Architecture whitepaper:  ...This is commonly referred to as the “100GB content database size limitation”. In fact, this is not a true limitation but rather a recommendation. SQL Server databases have been scaling far beyond 100GB for years now. Practically speaking, the recommendation is based primarily on two significant factors:    Service Level Agreement (SLA) requirements for a given organization may dictate that backup operations for the SharePoint databases must be executable in a limited amount of time. The size of the content databases will have a direct impact on how long it takes to execute that backup.    The storage subsystem must be robust enough to handle the disk I/O requirements of the SharePoint solution that it serves.    As long as a given organization is able to mitigate these two considerations, then the content databases can be allowed to grow. Real world implementations have seen successful SharePoint deployments that have implemented database sizes of 100GB, 150GB, 200GB, 250GB, 300GB, 350GB and 400GB. ","machine":{"os":"win 8","ram":8589934592}}
{"index":"rankin-2015.05.13","@timestamp":"2015-05-13T19:14:46.938Z","ip":"134.198.192.236","extension":"css","response":"200","geo":{"coordinates":{"lat":48.17793861,"lon":-103.6423467},"src":"CN","dest":"IN","srcdest":"CN:IN"},"@tags":["success","security"],"referer":"http://nytimes.com/success/rodolfo-neri-vela","agent":"Mozilla/5.0 (X11; Linux x86_64; rv:6.0a1) Gecko/20110421 Firefox/6.0a1","bytes":7918,"host":"cdn.theacademyofperformingartsandscience.org","request":"/styles/ads.css","url":"https://cdn.theacademyofperformingartsandscience.org/styles/ads.css","text":" From the Cygwin web site:  How can I make my own portable Cygwin on CD?  While some users have successfully done this, for example Indiana University's XLiveCD http://xlivecd.indiana.edu/, there is no easy way to do it. Full instructions for constructing a porttable Cygwin on CD by hand can be found on the mailing list at http://www.cygwin.com/ml/cygwin/2003-07/msg01117.html. (Thanks to fergus at bonhard dot uklinux dot net for these instructions.) ","machine":{"os":"win 7","ram":15032385536}}
{"index":"rankin-2015.05.14","@timestamp":"2015-05-14T14:58:48.692Z","ip":"215.60.101.114","extension":"gif","response":"200","geo":{"coordinates":{"lat":40.49522139,"lon":-107.5216467},"src":"IN","dest":"CM","srcdest":"IN:CM"},"@tags":["success","security"],"referer":"http://twitter.com/success/james-mcdivitt","agent":"Mozilla/5.0 (X11; Linux x86_64; rv:6.0a1) Gecko/20110421 Firefox/6.0a1","bytes":643,"host":"motion-media.theacademyofperformingartsandscience.org","request":"/canhaz/bonnie-j-dunbar.gif","url":"https://motion-media.theacademyofperformingartsandscience.org/canhaz/bonnie-j-dunbar.gif","text":" My argument for not doing leaving your network unsecured, is the same as that of Jon Rhoades and Alakdae: You're responsible for any traffic over your connection, so you need to make sure that none of that traffic is going to get you in trouble.  What you may want to consider, if you do want to leave your wiFi open for people, is some sort of setup whereby unknown users get heavily restricted internet access.  The idea being that this will prevent anyone doing anything untoward that you may have to answer for, and allow you to provide unrestricted access only to people who you trust.  However, setups like this are non-trivial to put together without setting up two distinct wireless networks, which is probably more hassle than it is worth to be kind to your neighbours. ","machine":{"os":"win 7","ram":8589934592}}
{"index":"rankin-2015.05.15","@timestamp":"2015-05-15T00:13:58.828Z","ip":"3.213.225.10","extension":"jpg","response":"200","geo":{"coordinates":{"lat":43.08027611,"lon":-76.53837556},"src":"IN","dest":"US","srcdest":"IN:US"},"@tags":["success","security"],"referer":"http://twitter.com/error/philippe-perrin","agent":"Mozilla/5.0 (X11; Linux i686) AppleWebKit/534.24 (KHTML, like Gecko) Chrome/11.0.696.50 Safari/534.24","bytes":6160,"host":"media-for-the-masses.theacademyofperformingartsandscience.org","request":"/uploads/susan-still-kilrain.jpg","url":"https://media-for-the-masses.theacademyofperformingartsandscience.org/uploads/susan-still-kilrain.jpg","text":" Because one of our customers is running out of disk space, I need to extend his Raid5 with one more disk.  At the moment the raid5 contains 3x72gb harddisk. The harddisk i want to add is exactly the same one.   He's running Win2003std on a HP Pro Liant DL380 G3  what would be the best (fastest) way? and do i need to convert the partition to dynamic volume?   anybody tried that with the HP tools?  kind regards   sam ","machine":{"os":"osx","ram":6442450944}}